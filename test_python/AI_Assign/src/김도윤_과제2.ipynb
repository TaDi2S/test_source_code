{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import graphviz\n",
    "import pydotplus\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn import linear_model, tree, ensemble, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"device:{}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  0.105915  0.253844  0.081080    3.67      0  \n",
       "6 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/creditcard.csv'\n",
    "\n",
    "\n",
    "eda_df = pd.read_csv(data_path) # 데이터 불러오기\n",
    "eda_df.head(10) # 개수만큼 상위 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 정보:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(\"데이터 정보:\")\n",
    "print(eda_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "print(\"결측치\")\n",
    "print(eda_df.isnull().sum()) # 결측이 있는 행이 true니까 결측치가 있는 행이 몇개인지\n",
    "# 결측치 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 중복 데이터 확인\n",
    "print(eda_df.duplicated().sum())\n",
    "\n",
    "# 중복 데이터 삭제\n",
    "eda_df = eda_df.drop_duplicates()\n",
    "\n",
    "print(eda_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 분포:\n",
      "Class\n",
      "0    283253\n",
      "1       473\n",
      "Name: count, dtype: int64\n",
      "label shape: (283726,)\n",
      "\n",
      "num of negative label: 283253 / num of positive label: 473\n",
      "% of negative label: 99.83328986416473 / % of positive label: 0.1667101358352777\n",
      "sum:473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 라벨 분리\n",
    "label_df = eda_df['Class']\n",
    "eda_df = eda_df.drop(columns=['Class', 'Time']) # 시간은 관계 없어 보이니 지운다\n",
    "\n",
    "# 라벨 분포 확인\n",
    "label_dict = label_df.value_counts()\n",
    "\n",
    "print(\"클래스 분포:\")\n",
    "print(label_df.value_counts())\n",
    "\n",
    "print('label shape: {}'.format(label_df.shape))\n",
    "\n",
    "print('\\nnum of negative label: {} / num of positive label: {}'.format(label_dict[0], label_dict[1])) # 0의 발생 횟수와 1의 발생횟수 count\n",
    "print('% of negative label: {} / % of positive label: {}'.format(label_dict[0] / label_df.shape[0] * 100, label_dict[1] / label_df.shape[0] * 100)) # 퍼센테이지로 나타낸다.\n",
    "print('sum:{}\\n'.format(sum(label_df.to_numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (28799, 29)\n",
      "Test label shape: (28799,)\n"
     ]
    }
   ],
   "source": [
    "test_data_ratio = 0.1   # split 한 뒤에 비정상 데이터와 합칠 것이라서 일단은 적게 놓는다.\n",
    "# 원래 0.2 -> 0.05 로 하니 Precision가 상승하고 ReCall이 많이 떨어짐 0.005로 하니 더 떨어짐 0.1이 그 나마 괜찮은것 같음 \n",
    "random_state = 0\n",
    "\n",
    "# anomaly detection 세팅을 위해 정상 데이터와 사기 데이터를 분리\n",
    "eda_normal = eda_df[label_df == 0]\n",
    "eda_unnormal = eda_df[label_df == 1]\n",
    "\n",
    "# 학습 데이터는 정상 데이터로만 구성\n",
    "train_data, test_data, train_label, test_label = train_test_split(eda_normal, label_df[label_df == 0], test_size=test_data_ratio, random_state=random_state)\n",
    "\n",
    "# 테스트 데이터는 정상 + 사기 데이터로 구성\n",
    "test_data_concat = pd.concat([test_data, eda_unnormal])\n",
    "test_label_concat = pd.concat([test_label, label_df[label_df == 1]])\n",
    "\n",
    "# 데이터 스케일링\n",
    "# StandardScaler와 MinMaxScaler를 시도해보았는데, StandardScaler가 더 좋은 성능을 보여 사용.\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "eda_unnormal_sacled = scaler.transform(test_data)\n",
    "test_data_scaled = scaler.transform(test_data_concat)\n",
    "\n",
    "scaler_min_max = MinMaxScaler()\n",
    "train_data_scaled_minmax = scaler.fit_transform(train_data)\n",
    "eda_unnormal_sacled_minmax = scaler.transform(test_data)\n",
    "test_data_scaled_minmax = scaler.transform(test_data_concat)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Test data shape: {test_data_scaled.shape}\")\n",
    "print(f\"Test label shape: {test_label_concat.values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-3    # 한번 학습을 시키는데 적용하는 정도\n",
    "\n",
    "# 모델 정의\n",
    "input_size = 29   # feature의 수\n",
    "# 레이어 수를 변경해 보기, 큰 변화는 보이지 않음\n",
    "encoder_hidden_size1 = 64\n",
    "encoder_hidden_size2 = 32\n",
    "encoder_hidden_size3 = 16\n",
    "decoder_hidden_size1 = 16\n",
    "decoder_hidden_size2 = 32\n",
    "decoder_hidden_size3 = 64\n",
    "# 드랍아웃 설정해 봤지만 변화 없음\n",
    "dropout_p = 0.2\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size, encoder_hidden_size1, encoder_hidden_size2, encoder_hidden_size3, decoder_hidden_size1, decoder_hidden_size2, decoder_hidden_size3):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.encoder_hidden_size1 = encoder_hidden_size1\n",
    "        self.encoder_hidden_size2 = encoder_hidden_size2\n",
    "        self.encoder_hidden_size3 = encoder_hidden_size3\n",
    "        self.decoder_hidden_size1 = decoder_hidden_size1\n",
    "        self.decoder_hidden_size2 = decoder_hidden_size2\n",
    "        self.decoder_hidden_size3 = decoder_hidden_size3\n",
    "\n",
    "        # 인코더\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, encoder_hidden_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoder_hidden_size1, encoder_hidden_size2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoder_hidden_size2, encoder_hidden_size3),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        # 디코더\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(decoder_hidden_size1, decoder_hidden_size2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(decoder_hidden_size2, decoder_hidden_size3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(decoder_hidden_size3, input_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        # data = self.prepare_input(data)\n",
    "        encoder_result = self.encoder(data)\n",
    "        decoder_result = self.decoder(encoder_result)\n",
    "\n",
    "        return decoder_result\n",
    "    \n",
    "    def prepare_input(self, data):\n",
    "        flattened_data = data.view(data.size(0), -1)\n",
    "\n",
    "        return flattened_data\n",
    "\n",
    "\n",
    "auto_encoder = AutoEncoder(input_size, encoder_hidden_size1, encoder_hidden_size2, encoder_hidden_size3, decoder_hidden_size1, decoder_hidden_size2, decoder_hidden_size3).to(device)\n",
    "#  weight_decay=1e-5 -> 가중치 크기 제한, 큰 변화 없음\n",
    "optimizer = torch.optim.Adam(auto_encoder.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 5          # 딥러닝은 시간이 오래걸리니 일단 10, 10과 5가 별 차이가 없어서 5로 설정\n",
    "batch_size = 32\n",
    "criterion = nn.MSELoss(reduction='none')\n",
    "\n",
    "class Trainer:\n",
    "  def __init__(self, model, data_loader, optimizer, criterion, epochs, device):\n",
    "    self.model = model\n",
    "    self.data_loader = data_loader\n",
    "    self.optimizer = optimizer\n",
    "    self.criterion = criterion\n",
    "    self.epochs = epochs\n",
    "    self.device = device\n",
    "\n",
    "  def train(self):\n",
    "    self.model.train()\n",
    "    \n",
    "    for epoch in range(self.epochs):\n",
    "      for data,_ in self.data_loader: \n",
    "        data = data[0].to(self.device)\n",
    "        \n",
    "        self.optimizer.zero_grad()  # 옵티마이저 초기화\n",
    "        result = self.model(data)\n",
    "\n",
    "        result, label = result.reshape(data.size(0), -1), data.reshape(data.size(0), -1)\n",
    "        loss = self.criterion(result, label)\n",
    "\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(train_data_scaled, dtype=torch.float32), torch.tensor(train_label.values, dtype=torch.long))\n",
    "test_dataset = TensorDataset(torch.tensor(test_data_scaled, dtype=torch.float32), torch.tensor(test_label_concat.values, dtype=torch.long))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "auto_encoder_trainer = Trainer(auto_encoder, train_loader, optimizer, criterion, epochs, device)\n",
    "auto_encoder_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold (ROC-based): 2.3415164947509766\n",
      "Calculated threshold: 17.9104\n",
      "Accuracy: 0.9866\n",
      "Precision: 0.7000\n",
      "Recall: 0.3256\n",
      "F1 Score: 0.4444\n"
     ]
    }
   ],
   "source": [
    "num_visualization = 5\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "class Tester:\n",
    "  def __init__(self, model, data_loader, criterion, num_visualization, device, threshold=None):\n",
    "    self.model = model\n",
    "    self.data_loader = data_loader\n",
    "    self.criterion = criterion\n",
    "    self.num_visualization = num_visualization\n",
    "    self.device = device\n",
    "    self.reconstructed_data = []\n",
    "    self.threshold = threshold\n",
    "    \n",
    "  def calculate_reconstruction_error(self, data):\n",
    "    # 입력 데이터에 대한 재구성 오류를 계산.\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(self.device)\n",
    "        output = self.model(data)\n",
    "        output = output.view(data.size(0), -1)\n",
    "        data = data.view(data.size(0), -1)\n",
    "        loss = self.criterion(output, data)\n",
    "        # 형태 출력\n",
    "        # 배치별로 평균 손실 반환\n",
    "        return loss.mean(dim=1).cpu().numpy()\n",
    "      \n",
    "  def determine_threshold(self, errors):\n",
    "      # 재구성 오류를 기반으로 임계값을 결정.\n",
    "      mean = errors.mean()\n",
    "      std = errors.std()\n",
    "      threshold = mean + 3 * std  # 평균 + 3 * 표준편차\n",
    "      return threshold     \n",
    "    \n",
    "  def test(self):\n",
    "    # 테스트 데이터를 사용하여 모델의 성능을 평가.\n",
    "    all_labels = []\n",
    "    all_errors = []\n",
    "\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, labels in self.data_loader:\n",
    "            data = data.to(self.device)\n",
    "            labels = labels.numpy()\n",
    "            errors = self.calculate_reconstruction_error(data)\n",
    "            all_labels.extend(labels)\n",
    "            all_errors.extend(errors)\n",
    "            if len(labels) != len(errors):\n",
    "              print(\"data is diff\")\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_errors = np.array(all_errors)\n",
    "    # 임계값을 95 백분위수 기반으로 하게 되면 ReCall은 오르지만 Precision이 지나치게 떨어짐\n",
    "    # self.threshold = np.percentile(all_errors, 98.6)\n",
    "    \n",
    "    # ROC Curve 계산\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_errors)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Youden's J statistic 계산\n",
    "    youden_j = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_j)\n",
    "    threshold = thresholds[optimal_idx]\n",
    "    print(f\"Optimal Threshold (ROC-based): {threshold}\")\n",
    "    \n",
    "    # 임계값이 설정되지 않은 경우 계산\n",
    "    if self.threshold is None:\n",
    "        self.threshold = self.determine_threshold(all_errors)\n",
    "        print(f'Calculated threshold: {self.threshold:.4f}')\n",
    "    \n",
    "    # 재구성 오류를 기반으로 이상치 예측\n",
    "    predictions = (all_errors > self.threshold).astype(int)\n",
    "\n",
    "    # 성능 지표 계산\n",
    "    accuracy = accuracy_score(all_labels, predictions)\n",
    "    precision = precision_score(all_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(all_labels, predictions, zero_division=0)\n",
    "    f1 = f1_score(all_labels, predictions, zero_division=0)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "\n",
    "auto_encoder_tester = Tester(auto_encoder, test_loader, criterion, num_visualization, device)\n",
    "auto_encoder_tester.test()\n",
    "\n",
    "# 전부 다 해봤지만 ReCall이 오르면 Precision이 떨어지고 Precision이 오르면 ReCall이 오릅니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a7b1bb636bc5912b8e04aaa547b4bbddd3e2f2287ba3fbb469f3183d5bbf320"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
